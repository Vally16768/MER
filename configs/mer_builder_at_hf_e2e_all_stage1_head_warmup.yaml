dataset:
  name: MER_BUILDER_AT_HF_E2E_ALL_STAGE1
  num_classes: 7
  class_names:
    - anger
    - disgust
    - fear
    - joy
    - neutral
    - sadness
    - surprise

modalities: [A, T]

data:
  processed_dir: mer_dataset_builder/data/processed
  train_splits: [train, meld_train]
  val_splits: [val, meld_dev]
  eval_splits: [testB]
  max_audio_sec: 12.0
  text_max_tokens: 320
  include_speaker_in_text: true
  meld_context_window: 5
  meld_context_sep: " </s> "
  num_workers: 4
  loader:
    persistent_workers: true
    prefetch_factor: 2
  filter:
    include_datasets_eval: [MELD]

model:
  audio_model: microsoft/wavlm-base
  text_model: roberta-base
  pool_audio: mean_std
  pool_text: cls
  # Stage-1: train only fusion/head quickly.
  freeze_audio: true
  freeze_text: true
  freeze_audio_feature_encoder: true
  hidden_dim: 256
  num_layers: 4
  num_heads: 8
  ffn_mult: 4
  modality_dropout_p: 0.0

training:
  device: auto
  seed: 42
  batch_size: 8
  epochs: 5
  # Higher LR is OK because only fusion/head is trainable.
  learning_rate: 1.0e-3
  lr_audio: 0.0
  lr_text: 0.0
  weight_decay: 1.0e-4
  optimizer: adamw
  class_weights: balanced
  label_smoothing: 0.1
  grad_clip_norm: 1.0
  amp: true
  grad_accum_steps: 4
  scheduler:
    type: reduceonplateau
    metric: uar
    mode: max
    factor: 0.5
    patience: 1
    min_lr: 1.0e-6
  patience: 2
  min_delta: 1.0e-4
  sampling:
    type: weighted
    dataset_weights:
      MELD: 6.0
  best_metric: UAR

output:
  root_dir: outputs

